{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ffn_multi_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1vameHmB3dvmcCEGuO8eNZbwhVYXiA9-j",
      "authorship_tag": "ABX9TyOMAdZWeFa+/T+AuQzJ0UvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visheshagrawal/Deep_Learning_Sequences/blob/master/ffn_multi_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9C9nKlvaAMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "tr=datasets.MNIST(\"\",train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "train = np.load('reduced_train.npz')\n",
        "x_train = train['X_train']\n",
        "# x_train = torch.from_numpy(x_train)\n",
        "y_train = train['y_train']\n",
        "# y_train = torch.from_numpy(y_train)\n",
        "mask_train = train['mask_train']\n",
        "#print(x_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWnoT-ghc7br",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5f58ae7f-92ba-424d-bbdf-18ef688981f4"
      },
      "source": [
        "z_train = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
        "print(z_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor(6.))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtVruufYckBl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOXWmSukfkWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e270ef7-1364-4495-e2fd-50918571c43a"
      },
      "source": [
        "val = np.load('reduced_val.npz')\n",
        "x_val = val['X_val']\n",
        "#x_val = torch.from_numpy(x_val)\n",
        "y_val = val['y_val']\n",
        "#y_val = torch.from_numpy(y_val)\n",
        "mask_val = val['mask_val']\n",
        "print(x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(635, 400, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W_liwD0sj4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "dbad38ca-fbd1-4393-b33c-6d2771944ae8"
      },
      "source": [
        "z_test = torch.utils.data.TensorDataset(torch.Tensor(x_val), torch.Tensor(y_val))\n",
        "print(z_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.2400, 0.0000, 0.2700,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor(6.))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V-dd64dqEM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader= torch.utils.data.DataLoader(z_train,64,True)\n",
        "#print(z_train)\n",
        "#print(train_loader)\n",
        "test_loader= torch.utils.data.DataLoader(z_test,64,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRRbHpjg67S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "seq_len = 400\n",
        "n_feat = 20\n",
        "n_hid = 30\n",
        "n_class = 10\n",
        "lr = 0.0025\n",
        "n_filt = 10\n",
        "drop_prob = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HvmndzzN2Hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b744ef8f-a7bb-4eb9-91a3-df4a28ace991"
      },
      "source": [
        "for batch_idx,(data,target) in enumerate(train_loader):\n",
        "  print(batch_idx)\n",
        "  print(data.view(64,-1).size())\n",
        "  print(target.size())\n",
        "  break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([64, 8000])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPnertrZ25Ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d456e5a5-e8d9-4c4b-bb66-3918c8588f42"
      },
      "source": [
        "for data,target in test_loader:\n",
        "  print(data.view(64,-1).size())\n",
        "  print(target.size())\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 8000])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4OZDJWTa6ZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94015c01-055d-40ae-9c36-1702bcd784c0"
      },
      "source": [
        "model=nn.Sequential(nn.Linear(8000,n_hid),nn.ReLU(),nn.Linear(n_hid,n_class),nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion= nn.NLLLoss()\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.003)\n",
        "\n",
        "epochs=10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  running_loss=0\n",
        "  for batch_idx,(data,target) in enumerate(train_loader):\n",
        "    data=data.view(-1,8000) \n",
        "    target=target.type(torch.LongTensor)\n",
        "    # print(data.shape)\n",
        "    # print(target)\n",
        "    data, target = Variable(data), Variable(target)\n",
        "    # print(data)\n",
        "    # print(target)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss=criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if batch_idx % 10 == 0:\n",
        "    #if True:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "      epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "      100. * batch_idx / len(train_loader), loss.item()))\n",
        "  \n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data=data.view(-1,8000)\n",
        "    target=target.type(torch.LongTensor)\n",
        "    data, target = Variable(data, volatile=True), Variable(target)\n",
        "    output = model(data)\n",
        "    # sum up batch loss\n",
        "    test_loss += criterion(output,target)\n",
        "    # get the index of the max log-probability\n",
        "    pred = output.data.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))\n",
        "  print(\"Epoch finished\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/2423 (0%)]\tLoss: 2.339217\n",
            "Train Epoch: 0 [640/2423 (26%)]\tLoss: 1.889902\n",
            "Train Epoch: 0 [1280/2423 (53%)]\tLoss: 1.645668\n",
            "Train Epoch: 0 [1920/2423 (79%)]\tLoss: 1.571895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0232, Accuracy: 307/635 (48%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 1 [0/2423 (0%)]\tLoss: 1.204122\n",
            "Train Epoch: 1 [640/2423 (26%)]\tLoss: 0.970637\n",
            "Train Epoch: 1 [1280/2423 (53%)]\tLoss: 0.923423\n",
            "Train Epoch: 1 [1920/2423 (79%)]\tLoss: 0.710859\n",
            "\n",
            "Test set: Average loss: 0.0163, Accuracy: 448/635 (71%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 2 [0/2423 (0%)]\tLoss: 0.562313\n",
            "Train Epoch: 2 [640/2423 (26%)]\tLoss: 0.542977\n",
            "Train Epoch: 2 [1280/2423 (53%)]\tLoss: 0.347559\n",
            "Train Epoch: 2 [1920/2423 (79%)]\tLoss: 0.396190\n",
            "\n",
            "Test set: Average loss: 0.0136, Accuracy: 468/635 (74%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 3 [0/2423 (0%)]\tLoss: 0.213985\n",
            "Train Epoch: 3 [640/2423 (26%)]\tLoss: 0.241018\n",
            "Train Epoch: 3 [1280/2423 (53%)]\tLoss: 0.187848\n",
            "Train Epoch: 3 [1920/2423 (79%)]\tLoss: 0.154809\n",
            "\n",
            "Test set: Average loss: 0.0125, Accuracy: 475/635 (75%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 4 [0/2423 (0%)]\tLoss: 0.108677\n",
            "Train Epoch: 4 [640/2423 (26%)]\tLoss: 0.107275\n",
            "Train Epoch: 4 [1280/2423 (53%)]\tLoss: 0.082676\n",
            "Train Epoch: 4 [1920/2423 (79%)]\tLoss: 0.071982\n",
            "\n",
            "Test set: Average loss: 0.0125, Accuracy: 487/635 (77%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 5 [0/2423 (0%)]\tLoss: 0.109100\n",
            "Train Epoch: 5 [640/2423 (26%)]\tLoss: 0.061491\n",
            "Train Epoch: 5 [1280/2423 (53%)]\tLoss: 0.043520\n",
            "Train Epoch: 5 [1920/2423 (79%)]\tLoss: 0.031730\n",
            "\n",
            "Test set: Average loss: 0.0123, Accuracy: 482/635 (76%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 6 [0/2423 (0%)]\tLoss: 0.037719\n",
            "Train Epoch: 6 [640/2423 (26%)]\tLoss: 0.026249\n",
            "Train Epoch: 6 [1280/2423 (53%)]\tLoss: 0.024001\n",
            "Train Epoch: 6 [1920/2423 (79%)]\tLoss: 0.024903\n",
            "\n",
            "Test set: Average loss: 0.0121, Accuracy: 491/635 (77%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 7 [0/2423 (0%)]\tLoss: 0.014553\n",
            "Train Epoch: 7 [640/2423 (26%)]\tLoss: 0.019727\n",
            "Train Epoch: 7 [1280/2423 (53%)]\tLoss: 0.019596\n",
            "Train Epoch: 7 [1920/2423 (79%)]\tLoss: 0.015317\n",
            "\n",
            "Test set: Average loss: 0.0125, Accuracy: 491/635 (77%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 8 [0/2423 (0%)]\tLoss: 0.011777\n",
            "Train Epoch: 8 [640/2423 (26%)]\tLoss: 0.011091\n",
            "Train Epoch: 8 [1280/2423 (53%)]\tLoss: 0.014515\n",
            "Train Epoch: 8 [1920/2423 (79%)]\tLoss: 0.012901\n",
            "\n",
            "Test set: Average loss: 0.0126, Accuracy: 494/635 (78%)\n",
            "\n",
            "Epoch finished\n",
            "Train Epoch: 9 [0/2423 (0%)]\tLoss: 0.097057\n",
            "Train Epoch: 9 [640/2423 (26%)]\tLoss: 0.012477\n",
            "Train Epoch: 9 [1280/2423 (53%)]\tLoss: 0.010060\n",
            "Train Epoch: 9 [1920/2423 (79%)]\tLoss: 0.008887\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 490/635 (77%)\n",
            "\n",
            "Epoch finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EbeYk5ScmUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "7a940e6d-2193-464a-fdb7-e801248a4756"
      },
      "source": [
        "  for epoch in range(epochs):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "      data=data.view(-1,8000)\n",
        "      target=target.type(torch.LongTensor)\n",
        "      data, target = Variable(data, volatile=True), Variable(target)\n",
        "      output = model(data)\n",
        "      # sum up batch loss\n",
        "      test_loss += criterion(output,target)\n",
        "      # get the index of the max log-probability\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0130, Accuracy: 480/635 (76%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}